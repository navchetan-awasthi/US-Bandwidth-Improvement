{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tOG84vhD_Fgr"
   },
   "outputs": [],
   "source": [
    "#import the neccesary libraries\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import skimage\n",
    "import skimage.transform\n",
    "import os\n",
    "import tensorflow.keras.backend as K\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "import math\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from sobel_edge import sobel \n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "12000\n",
      "13000\n",
      "14000\n",
      "15000\n",
      "16000\n",
      "17000\n",
      "18000\n",
      "19000\n",
      "20000\n",
      "21000\n",
      "22000\n",
      "23000\n",
      "24000\n",
      "25000\n",
      "Done\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "import skimage.transform\n",
    "def CreateSet(input_list,input_dir,output_dir,N_patches,patchsize,H,W):\n",
    "    \"\"\"\n",
    "    Creates an array that can be used as input and output for the model\n",
    "    parameters: input_list, a list with indices of the images that are used\n",
    "                N_patches, the amount of image patches the model creates per image\n",
    "                patchsize, the width and height of the square image patch\n",
    "    \n",
    "    \"\"\"\n",
    "    X = np.zeros((len(input_list)*N_patches, patchsize, patchsize, 2), dtype=np.float32)\n",
    "    y = np.zeros((len(input_list)*N_patches, patchsize, patchsize, 1), dtype=np.float32)\n",
    "    for j in range(N_patches):\n",
    "        for n,i in enumerate(input_list):\n",
    "            #random pixel location\n",
    "            ii = j*len(input_list)+n\n",
    "            xloc = random.randint(0,W-patchsize)\n",
    "            yloc = random.randint(0,H-patchsize)\n",
    "            #input \n",
    "            img_input1 = Image.open('bandLimited_model1/input_%03d.png' % (i+1))\n",
    "            in_img_input1 = tf.keras.preprocessing.image.img_to_array(img_input1)\n",
    "            in_img_input1 = in_img_input1[yloc:yloc+patchsize,xloc:xloc+patchsize]\n",
    "            in_img_input1 = skimage.transform.resize(in_img_input1 , (patchsize , patchsize , 1) , mode = 'constant' , preserve_range = True)\n",
    "            #2nd input\n",
    "            img_input2 = Image.open('bandLimited_model2/input_%03d.png' % (i+1))\n",
    "            in_img_input2 = tf.keras.preprocessing.image.img_to_array(img_input2)\n",
    "            in_img_input2 = in_img_input2[yloc:yloc+patchsize,xloc:xloc+patchsize]\n",
    "            in_img_input2 = skimage.transform.resize(in_img_input2 , (patchsize , patchsize , 1) , mode = 'constant' , preserve_range = True)\n",
    "            \n",
    "            X1 = in_img_input1 / 255.0\n",
    "            X2 = in_img_input2 / 255.0\n",
    "            X[ii] = np.concatenate((X1,X2),axis=-1)\n",
    "            \n",
    "            #output\n",
    "            img_output = Image.open('groundTruth/target_%03d.png' % (i+1))\n",
    "            in_img_output = tf.keras.preprocessing.image.img_to_array(img_output)\n",
    "            in_img_output = in_img_output[yloc:yloc+patchsize,xloc:xloc+patchsize]\n",
    "            in_img_output = skimage.transform.resize(in_img_output , (patchsize , patchsize , 1) , mode = 'constant' , preserve_range = True)\n",
    "            y[ii] = in_img_output / 255.0\n",
    "            if ii % 1000 == 0:\n",
    "                print(ii)\n",
    "    print('Done')\n",
    "    return X,y\n",
    "#This function can be used for small datasets \n",
    "#amount of patches per image\n",
    "N_patches = 64\n",
    "#width and height of the patches\n",
    "patchsize = 128\n",
    "#image dimensions\n",
    "H=801\n",
    "W=401\n",
    "input_dir = 'bandLimited'\n",
    "output_dir = 'groundTruth'\n",
    "# input_dir = 'CIRSBandLimited'\n",
    "# output_dir = 'CIRSGroundTruth'\n",
    "# input_dir = 'carotidBandLimited'\n",
    "# output_dir = 'carotidGroundTruth'\n",
    "\n",
    "#Train set is image 1 till 401\n",
    "X_train,y_train = CreateSet(range(401),input_dir,output_dir,N_patches,patchsize,H,W)\n",
    "#validation set is image 402 till 535\n",
    "X_valid,y_valid = CreateSet(range(401,535),input_dir,output_dir,N_patches,patchsize,H,W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Xt_4VuyFAzRI"
   },
   "outputs": [],
   "source": [
    "def SRCNN():\n",
    "    # lrelu = LeakyReLU(alpha=0.1)\n",
    "    SRCNN = tf.keras.Sequential()\n",
    "    SRCNN.add(tf.keras.layers.Conv2D(filters=128, kernel_size= (9,9),  kernel_initializer='glorot_uniform',\n",
    "                     activation='relu', padding='same', input_shape=(None, None, 2)))\n",
    "    SRCNN.add(tf.keras.layers.Conv2D(filters=64, kernel_size= (3,3),  kernel_initializer='glorot_uniform',\n",
    "                     activation='relu', padding='same'))\n",
    "    # SRCNN.add(BatchNormalization())\n",
    "    SRCNN.add(tf.keras.layers.Conv2D(filters=1, kernel_size= (5,5),  kernel_initializer='glorot_uniform',\n",
    "                     activation='linear', padding='same'))\n",
    "    adam = tf.keras.optimizers.Adam(lr=0.0003)\n",
    "    SRCNN.compile(optimizer=adam, loss=tf.keras.losses.MeanSquaredError(), metrics=[tf.keras.metrics.RootMeanSquaredError()])\n",
    "    return SRCNN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 138
    },
    "colab_type": "code",
    "id": "P6bKNYDv8PxF",
    "outputId": "53c556e0-1b76-409a-c4aa-ba58c472930e"
   },
   "outputs": [],
   "source": [
    "#define and compile the model\n",
    "# img_tensor = tf.keras.layers.Input((None , None , 1) , name = 'img_tensor')\n",
    "model = SRCNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Hx0xnc4kANzc"
   },
   "outputs": [],
   "source": [
    "model_path = 'model_SRCNN_DoubleInput_ultrasound.h5'\n",
    "callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping(patience=10, verbose=1),\n",
    "    tf.keras.callbacks.ReduceLROnPlateau(factor=0.1, patience=5, min_lr=0.0001, verbose=1),\n",
    "    tf.keras.callbacks.ModelCheckpoint(model_path, verbose=1, save_best_only=True, save_weights_only=True)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uXgvQE67EC8G"
   },
   "outputs": [],
   "source": [
    "#load the model\n",
    "model.load_weights(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 2772
    },
    "colab_type": "code",
    "id": "ewoQSgb9-Owo",
    "outputId": "e7d76ce5-ee4d-42a5-9437-9be4dc6ccb98"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_9 (Conv2D)            (None, None, None, 128)   20864     \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, None, None, 64)    73792     \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, None, None, 1)     1601      \n",
      "=================================================================\n",
      "Total params: 96,257\n",
      "Trainable params: 96,257\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1616
    },
    "colab_type": "code",
    "id": "jiBmsTy_Anok",
    "outputId": "d350828c-a393-41ad-89f8-38123f726333",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1604/1604 [==============================] - ETA: 0s - loss: 0.0086 - root_mean_squared_error: 0.0929\n",
      "Epoch 00001: val_loss improved from inf to 0.00882, saving model to model_SRCNN_DoubleInput_ultrasound.h5\n",
      "1604/1604 [==============================] - 37s 23ms/step - loss: 0.0086 - root_mean_squared_error: 0.0929 - val_loss: 0.0088 - val_root_mean_squared_error: 0.0939 - lr: 3.0000e-04\n",
      "Epoch 2/100\n",
      "1602/1604 [============================>.] - ETA: 0s - loss: 0.0083 - root_mean_squared_error: 0.0913\n",
      "Epoch 00002: val_loss improved from 0.00882 to 0.00873, saving model to model_SRCNN_DoubleInput_ultrasound.h5\n",
      "1604/1604 [==============================] - 37s 23ms/step - loss: 0.0083 - root_mean_squared_error: 0.0913 - val_loss: 0.0087 - val_root_mean_squared_error: 0.0934 - lr: 3.0000e-04\n",
      "Epoch 3/100\n",
      "1603/1604 [============================>.] - ETA: 0s - loss: 0.0083 - root_mean_squared_error: 0.0911\n",
      "Epoch 00003: val_loss improved from 0.00873 to 0.00871, saving model to model_SRCNN_DoubleInput_ultrasound.h5\n",
      "1604/1604 [==============================] - 37s 23ms/step - loss: 0.0083 - root_mean_squared_error: 0.0911 - val_loss: 0.0087 - val_root_mean_squared_error: 0.0933 - lr: 3.0000e-04\n",
      "Epoch 4/100\n",
      "1603/1604 [============================>.] - ETA: 0s - loss: 0.0083 - root_mean_squared_error: 0.0911\n",
      "Epoch 00004: val_loss improved from 0.00871 to 0.00870, saving model to model_SRCNN_DoubleInput_ultrasound.h5\n",
      "1604/1604 [==============================] - 38s 23ms/step - loss: 0.0083 - root_mean_squared_error: 0.0911 - val_loss: 0.0087 - val_root_mean_squared_error: 0.0933 - lr: 3.0000e-04\n",
      "Epoch 5/100\n",
      "1602/1604 [============================>.] - ETA: 0s - loss: 0.0083 - root_mean_squared_error: 0.0910\n",
      "Epoch 00005: val_loss improved from 0.00870 to 0.00870, saving model to model_SRCNN_DoubleInput_ultrasound.h5\n",
      "1604/1604 [==============================] - 37s 23ms/step - loss: 0.0083 - root_mean_squared_error: 0.0910 - val_loss: 0.0087 - val_root_mean_squared_error: 0.0933 - lr: 3.0000e-04\n",
      "Epoch 6/100\n",
      "1604/1604 [==============================] - ETA: 0s - loss: 0.0083 - root_mean_squared_error: 0.0910\n",
      "Epoch 00006: val_loss did not improve from 0.00870\n",
      "1604/1604 [==============================] - 37s 23ms/step - loss: 0.0083 - root_mean_squared_error: 0.0910 - val_loss: 0.0087 - val_root_mean_squared_error: 0.0933 - lr: 3.0000e-04\n",
      "Epoch 7/100\n",
      "1602/1604 [============================>.] - ETA: 0s - loss: 0.0083 - root_mean_squared_error: 0.0910\n",
      "Epoch 00007: val_loss improved from 0.00870 to 0.00869, saving model to model_SRCNN_DoubleInput_ultrasound.h5\n",
      "1604/1604 [==============================] - 37s 23ms/step - loss: 0.0083 - root_mean_squared_error: 0.0910 - val_loss: 0.0087 - val_root_mean_squared_error: 0.0932 - lr: 3.0000e-04\n",
      "Epoch 8/100\n",
      "1603/1604 [============================>.] - ETA: 0s - loss: 0.0083 - root_mean_squared_error: 0.0910\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 0.0001.\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.00869\n",
      "1604/1604 [==============================] - 37s 23ms/step - loss: 0.0083 - root_mean_squared_error: 0.0910 - val_loss: 0.0087 - val_root_mean_squared_error: 0.0933 - lr: 3.0000e-04\n",
      "Epoch 9/100\n",
      "1604/1604 [==============================] - ETA: 0s - loss: 0.0085 - root_mean_squared_error: 0.0920\n",
      "Epoch 00009: val_loss improved from 0.00869 to 0.00866, saving model to model_SRCNN_DoubleInput_ultrasound.h5\n",
      "1604/1604 [==============================] - 38s 23ms/step - loss: 0.0085 - root_mean_squared_error: 0.0920 - val_loss: 0.0087 - val_root_mean_squared_error: 0.0930 - lr: 1.0000e-04\n",
      "Epoch 10/100\n",
      "1602/1604 [============================>.] - ETA: 0s - loss: 0.0085 - root_mean_squared_error: 0.0920\n",
      "Epoch 00010: val_loss improved from 0.00866 to 0.00862, saving model to model_SRCNN_DoubleInput_ultrasound.h5\n",
      "1604/1604 [==============================] - 37s 23ms/step - loss: 0.0085 - root_mean_squared_error: 0.0920 - val_loss: 0.0086 - val_root_mean_squared_error: 0.0929 - lr: 1.0000e-04\n",
      "Epoch 11/100\n",
      "1604/1604 [==============================] - ETA: 0s - loss: 0.0085 - root_mean_squared_error: 0.0920\n",
      "Epoch 00011: val_loss did not improve from 0.00862\n",
      "1604/1604 [==============================] - 36s 23ms/step - loss: 0.0085 - root_mean_squared_error: 0.0920 - val_loss: 0.0087 - val_root_mean_squared_error: 0.0931 - lr: 1.0000e-04\n",
      "Epoch 12/100\n",
      "1603/1604 [============================>.] - ETA: 0s - loss: 0.0084 - root_mean_squared_error: 0.0919\n",
      "Epoch 00012: val_loss improved from 0.00862 to 0.00861, saving model to model_SRCNN_DoubleInput_ultrasound.h5\n",
      "1604/1604 [==============================] - 37s 23ms/step - loss: 0.0084 - root_mean_squared_error: 0.0919 - val_loss: 0.0086 - val_root_mean_squared_error: 0.0928 - lr: 1.0000e-04\n",
      "Epoch 13/100\n",
      "1603/1604 [============================>.] - ETA: 0s - loss: 0.0084 - root_mean_squared_error: 0.0919\n",
      "Epoch 00013: val_loss did not improve from 0.00861\n",
      "1604/1604 [==============================] - 36s 23ms/step - loss: 0.0084 - root_mean_squared_error: 0.0919 - val_loss: 0.0086 - val_root_mean_squared_error: 0.0928 - lr: 1.0000e-04\n",
      "Epoch 14/100\n",
      "1603/1604 [============================>.] - ETA: 0s - loss: 0.0084 - root_mean_squared_error: 0.0918\n",
      "Epoch 00014: val_loss did not improve from 0.00861\n",
      "1604/1604 [==============================] - 36s 23ms/step - loss: 0.0084 - root_mean_squared_error: 0.0918 - val_loss: 0.0086 - val_root_mean_squared_error: 0.0928 - lr: 1.0000e-04\n",
      "Epoch 15/100\n",
      "1603/1604 [============================>.] - ETA: 0s - loss: 0.0084 - root_mean_squared_error: 0.0918\n",
      "Epoch 00015: val_loss did not improve from 0.00861\n",
      "1604/1604 [==============================] - 37s 23ms/step - loss: 0.0084 - root_mean_squared_error: 0.0918 - val_loss: 0.0086 - val_root_mean_squared_error: 0.0928 - lr: 1.0000e-04\n",
      "Epoch 16/100\n",
      "1603/1604 [============================>.] - ETA: 0s - loss: 0.0084 - root_mean_squared_error: 0.0918\n",
      "Epoch 00016: val_loss did not improve from 0.00861\n",
      "1604/1604 [==============================] - 36s 22ms/step - loss: 0.0084 - root_mean_squared_error: 0.0918 - val_loss: 0.0086 - val_root_mean_squared_error: 0.0928 - lr: 1.0000e-04\n",
      "Epoch 17/100\n",
      "1602/1604 [============================>.] - ETA: 0s - loss: 0.0084 - root_mean_squared_error: 0.0917\n",
      "Epoch 00017: val_loss improved from 0.00861 to 0.00861, saving model to model_SRCNN_DoubleInput_ultrasound.h5\n",
      "1604/1604 [==============================] - 37s 23ms/step - loss: 0.0084 - root_mean_squared_error: 0.0917 - val_loss: 0.0086 - val_root_mean_squared_error: 0.0928 - lr: 1.0000e-04\n",
      "Epoch 18/100\n",
      "1603/1604 [============================>.] - ETA: 0s - loss: 0.0084 - root_mean_squared_error: 0.0917\n",
      "Epoch 00018: val_loss did not improve from 0.00861\n",
      "1604/1604 [==============================] - 37s 23ms/step - loss: 0.0084 - root_mean_squared_error: 0.0917 - val_loss: 0.0086 - val_root_mean_squared_error: 0.0928 - lr: 1.0000e-04\n",
      "Epoch 19/100\n",
      "1603/1604 [============================>.] - ETA: 0s - loss: 0.0084 - root_mean_squared_error: 0.0917\n",
      "Epoch 00019: val_loss did not improve from 0.00861\n",
      "1604/1604 [==============================] - 37s 23ms/step - loss: 0.0084 - root_mean_squared_error: 0.0917 - val_loss: 0.0086 - val_root_mean_squared_error: 0.0928 - lr: 1.0000e-04\n",
      "Epoch 20/100\n",
      "1604/1604 [==============================] - ETA: 0s - loss: 0.0084 - root_mean_squared_error: 0.0916\n",
      "Epoch 00020: val_loss did not improve from 0.00861\n",
      "1604/1604 [==============================] - 37s 23ms/step - loss: 0.0084 - root_mean_squared_error: 0.0916 - val_loss: 0.0086 - val_root_mean_squared_error: 0.0928 - lr: 1.0000e-04\n",
      "Epoch 21/100\n",
      "1603/1604 [============================>.] - ETA: 0s - loss: 0.0084 - root_mean_squared_error: 0.0916\n",
      "Epoch 00021: val_loss improved from 0.00861 to 0.00861, saving model to model_SRCNN_DoubleInput_ultrasound.h5\n",
      "1604/1604 [==============================] - 36s 22ms/step - loss: 0.0084 - root_mean_squared_error: 0.0916 - val_loss: 0.0086 - val_root_mean_squared_error: 0.0928 - lr: 1.0000e-04\n",
      "Epoch 22/100\n",
      "1603/1604 [============================>.] - ETA: 0s - loss: 0.0084 - root_mean_squared_error: 0.0916\n",
      "Epoch 00022: val_loss improved from 0.00861 to 0.00861, saving model to model_SRCNN_DoubleInput_ultrasound.h5\n",
      "1604/1604 [==============================] - 37s 23ms/step - loss: 0.0084 - root_mean_squared_error: 0.0916 - val_loss: 0.0086 - val_root_mean_squared_error: 0.0928 - lr: 1.0000e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/100\n",
      "1603/1604 [============================>.] - ETA: 0s - loss: 0.0084 - root_mean_squared_error: 0.0915\n",
      "Epoch 00023: val_loss did not improve from 0.00861\n",
      "1604/1604 [==============================] - 36s 22ms/step - loss: 0.0084 - root_mean_squared_error: 0.0916 - val_loss: 0.0086 - val_root_mean_squared_error: 0.0928 - lr: 1.0000e-04\n",
      "Epoch 24/100\n",
      "1604/1604 [==============================] - ETA: 0s - loss: 0.0084 - root_mean_squared_error: 0.0915\n",
      "Epoch 00024: val_loss improved from 0.00861 to 0.00861, saving model to model_SRCNN_DoubleInput_ultrasound.h5\n",
      "1604/1604 [==============================] - 37s 23ms/step - loss: 0.0084 - root_mean_squared_error: 0.0915 - val_loss: 0.0086 - val_root_mean_squared_error: 0.0928 - lr: 1.0000e-04\n",
      "Epoch 25/100\n",
      "1602/1604 [============================>.] - ETA: 0s - loss: 0.0084 - root_mean_squared_error: 0.0915\n",
      "Epoch 00025: val_loss improved from 0.00861 to 0.00861, saving model to model_SRCNN_DoubleInput_ultrasound.h5\n",
      "1604/1604 [==============================] - 36s 23ms/step - loss: 0.0084 - root_mean_squared_error: 0.0915 - val_loss: 0.0086 - val_root_mean_squared_error: 0.0928 - lr: 1.0000e-04\n",
      "Epoch 26/100\n",
      "1603/1604 [============================>.] - ETA: 0s - loss: 0.0084 - root_mean_squared_error: 0.0915\n",
      "Epoch 00026: val_loss did not improve from 0.00861\n",
      "1604/1604 [==============================] - 37s 23ms/step - loss: 0.0084 - root_mean_squared_error: 0.0915 - val_loss: 0.0086 - val_root_mean_squared_error: 0.0928 - lr: 1.0000e-04\n",
      "Epoch 27/100\n",
      "1604/1604 [==============================] - ETA: 0s - loss: 0.0084 - root_mean_squared_error: 0.0915\n",
      "Epoch 00027: val_loss improved from 0.00861 to 0.00861, saving model to model_SRCNN_DoubleInput_ultrasound.h5\n",
      "1604/1604 [==============================] - 37s 23ms/step - loss: 0.0084 - root_mean_squared_error: 0.0915 - val_loss: 0.0086 - val_root_mean_squared_error: 0.0928 - lr: 1.0000e-04\n",
      "Epoch 28/100\n",
      "1603/1604 [============================>.] - ETA: 0s - loss: 0.0084 - root_mean_squared_error: 0.0915\n",
      "Epoch 00028: val_loss improved from 0.00861 to 0.00861, saving model to model_SRCNN_DoubleInput_ultrasound.h5\n",
      "1604/1604 [==============================] - 37s 23ms/step - loss: 0.0084 - root_mean_squared_error: 0.0915 - val_loss: 0.0086 - val_root_mean_squared_error: 0.0928 - lr: 1.0000e-04\n",
      "Epoch 29/100\n",
      "1603/1604 [============================>.] - ETA: 0s - loss: 0.0084 - root_mean_squared_error: 0.0915\n",
      "Epoch 00029: val_loss did not improve from 0.00861\n",
      "1604/1604 [==============================] - 37s 23ms/step - loss: 0.0084 - root_mean_squared_error: 0.0915 - val_loss: 0.0086 - val_root_mean_squared_error: 0.0928 - lr: 1.0000e-04\n",
      "Epoch 30/100\n",
      "1604/1604 [==============================] - ETA: 0s - loss: 0.0084 - root_mean_squared_error: 0.0915\n",
      "Epoch 00030: val_loss did not improve from 0.00861\n",
      "1604/1604 [==============================] - 36s 23ms/step - loss: 0.0084 - root_mean_squared_error: 0.0915 - val_loss: 0.0086 - val_root_mean_squared_error: 0.0928 - lr: 1.0000e-04\n",
      "Epoch 31/100\n",
      "1604/1604 [==============================] - ETA: 0s - loss: 0.0084 - root_mean_squared_error: 0.0915\n",
      "Epoch 00031: val_loss improved from 0.00861 to 0.00861, saving model to model_SRCNN_DoubleInput_ultrasound.h5\n",
      "1604/1604 [==============================] - 37s 23ms/step - loss: 0.0084 - root_mean_squared_error: 0.0915 - val_loss: 0.0086 - val_root_mean_squared_error: 0.0928 - lr: 1.0000e-04\n",
      "Epoch 32/100\n",
      "1603/1604 [============================>.] - ETA: 0s - loss: 0.0084 - root_mean_squared_error: 0.0915\n",
      "Epoch 00032: val_loss did not improve from 0.00861\n",
      "1604/1604 [==============================] - 37s 23ms/step - loss: 0.0084 - root_mean_squared_error: 0.0915 - val_loss: 0.0086 - val_root_mean_squared_error: 0.0928 - lr: 1.0000e-04\n",
      "Epoch 33/100\n",
      "1603/1604 [============================>.] - ETA: 0s - loss: 0.0084 - root_mean_squared_error: 0.0915\n",
      "Epoch 00033: val_loss did not improve from 0.00861\n",
      "1604/1604 [==============================] - 36s 23ms/step - loss: 0.0084 - root_mean_squared_error: 0.0915 - val_loss: 0.0086 - val_root_mean_squared_error: 0.0928 - lr: 1.0000e-04\n",
      "Epoch 34/100\n",
      "1603/1604 [============================>.] - ETA: 0s - loss: 0.0084 - root_mean_squared_error: 0.0915\n",
      "Epoch 00034: val_loss did not improve from 0.00861\n",
      "1604/1604 [==============================] - 37s 23ms/step - loss: 0.0084 - root_mean_squared_error: 0.0915 - val_loss: 0.0086 - val_root_mean_squared_error: 0.0928 - lr: 1.0000e-04\n",
      "Epoch 35/100\n",
      "1602/1604 [============================>.] - ETA: 0s - loss: 0.0084 - root_mean_squared_error: 0.0915\n",
      "Epoch 00035: val_loss did not improve from 0.00861\n",
      "1604/1604 [==============================] - 36s 23ms/step - loss: 0.0084 - root_mean_squared_error: 0.0915 - val_loss: 0.0086 - val_root_mean_squared_error: 0.0928 - lr: 1.0000e-04\n",
      "Epoch 36/100\n",
      "1603/1604 [============================>.] - ETA: 0s - loss: 0.0084 - root_mean_squared_error: 0.0915\n",
      "Epoch 00036: val_loss did not improve from 0.00861\n",
      "1604/1604 [==============================] - 37s 23ms/step - loss: 0.0084 - root_mean_squared_error: 0.0915 - val_loss: 0.0086 - val_root_mean_squared_error: 0.0928 - lr: 1.0000e-04\n",
      "Epoch 37/100\n",
      " 127/1604 [=>............................] - ETA: 28s - loss: 0.0084 - root_mean_squared_error: 0.0915"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-590a21a242fe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m results = model.fit(X_train,y_train, epochs=100, callbacks=callbacks,batch_size = 16,\n\u001b[0m\u001b[1;32m      3\u001b[0m                     validation_data=(X_valid,y_valid),shuffle=False)\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    853\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m               \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmp_logs\u001b[0m  \u001b[0;31m# No error, now safe to assign to logs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m         \u001b[0mepoch_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    387\u001b[0m     \"\"\"\n\u001b[1;32m    388\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_call_train_batch_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 389\u001b[0;31m       \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    390\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    391\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_process_logs\u001b[0;34m(self, logs)\u001b[0m\n\u001b[1;32m    263\u001b[0m     \u001b[0;34m\"\"\"Turns tensors into numpy arrays or Python scalars.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 265\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    266\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36mto_numpy_or_python_type\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    521\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    522\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 523\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    524\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    615\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    616\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 617\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    618\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    619\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    615\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    616\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 617\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    618\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    619\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36m_to_single_numpy_or_python_type\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    517\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 519\u001b[0;31m       \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    520\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    521\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    959\u001b[0m     \"\"\"\n\u001b[1;32m    960\u001b[0m     \u001b[0;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 961\u001b[0;31m     \u001b[0mmaybe_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    962\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    963\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    925\u001b[0m     \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    926\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 927\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    928\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    929\u001b[0m       \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#train the model\n",
    "results = model.fit(X_train,y_train, epochs=100, callbacks=callbacks,batch_size = 16,\n",
    "                    validation_data=(X_valid,y_valid),shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualise the accuracy and losses of the model\n",
    "# list all data in history\n",
    "print(results.history.keys())\n",
    "# summarize history for accuracy\n",
    "plt.plot(results.history['root_mean_squared_error'])\n",
    "plt.plot(results.history['val_root_mean_squared_error'])\n",
    "plt.title('model root_mean_squared_error')\n",
    "plt.ylabel('root_mean_squared_error')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(results.history['loss'])\n",
    "plt.plot(results.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n",
      "Done\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "#Create the arrays for the Test set which are the image 535 till 669\n",
    "def CreateTestSet(test_set_indices,input_dir_test,output_dir_test):\n",
    "    \"\"\"\n",
    "    Function that reads in the test sets images as arrays and scales them between 0 and 1\n",
    "    parameters:test_set_indices: The indices of the the images in the test set\n",
    "                 input_dir_test: The directory where the input png images are stored\n",
    "                output_dir_test: The directory where the output png images are stored\n",
    "    returns: Test_set_X: an array of input images\n",
    "             Test_set_y: an array of output images\n",
    "    \"\"\"\n",
    "    Test_set_X = np.zeros((len(test_set_indices), 801, 401, 1), dtype=np.float32)\n",
    "    Test_set_y = np.zeros((len(test_set_indices), 801, 401, 1), dtype=np.float32)\n",
    "    for i,n in enumerate(test_set_indices):\n",
    "        img = Image.open(input_dir_test+'/input_%03d.png' % (n+1))\n",
    "        in_img_input = tf.keras.preprocessing.image.img_to_array(img)\n",
    "        in_img_input = skimage.transform.resize(in_img_input , (801 , 401 , 1) , mode = 'constant' , preserve_range = True)\n",
    "        Test_set_X[i] =in_img_input / 255.0\n",
    "\n",
    "        img = Image.open(output_dir_test+'/target_%03d.png' % (n+1))\n",
    "        in_img_output = tf.keras.preprocessing.image.img_to_array(img)\n",
    "        in_img_output = skimage.transform.resize(in_img_output , (801 , 401 , 1) , mode = 'constant' , preserve_range = True)\n",
    "        Test_set_y[i] =in_img_output / 255.0    \n",
    "    print('Done')\n",
    "    return Test_set_X, Test_set_y\n",
    "#Run for all the datasets\n",
    "for dataset in ['','CIRS_','carotid_']:\n",
    "    if dataset == '':\n",
    "        test_set_indices = range(535,669)\n",
    "        input_dir_test = 'bandLimited'\n",
    "        output_dir_test = 'groundTruth'\n",
    "    if dataset == 'CIRS_':\n",
    "        test_set_indices = range(11)\n",
    "        input_dir_test = 'CIRSBandLimited'\n",
    "        output_dir_test = 'CIRSGroundTruth'\n",
    "    if dataset =='carotid_':\n",
    "        test_set_indices = range(70)\n",
    "        input_dir_test = 'carotidBandLimited'\n",
    "        output_dir_test = 'carotidGroundTruth'\n",
    "    #define the input and output test sets\n",
    "    Test_set_X, Test_set_y = CreateTestSet(test_set_indices,input_dir_test,output_dir_test)\n",
    "    # load the npy files for model 1 and 2\n",
    "    val_set_model1 = np.load('Model_output_test_'+dataset+'SRCNNmodel1_ultrasound.npy')\n",
    "    val_set_model2 = np.load('Model_output_test_'+dataset+'SRCNNmodel2_ultrasound.npy')\n",
    "    MODEL1 = np.zeros([len(val_set_model1),801,401,1])\n",
    "    MODEL2 = np.zeros([len(val_set_model1),801,401,1])\n",
    "    for i in range(len(val_set_model1)):\n",
    "        img1 = skimage.transform.resize(val_set_model1[i] , (801 , 401 , 1) , mode = 'constant' , preserve_range = True)\n",
    "        img2 = skimage.transform.resize(val_set_model2[i] , (801, 401 , 1) , mode = 'constant' , preserve_range = True)\n",
    "        MODEL1[i] = img1\n",
    "        MODEL2[i] = img2\n",
    "    val_set_model1and2 = np.concatenate((MODEL1,MODEL2),axis=-1)\n",
    "    prediction_images = np.zeros_like(val_set_model1)\n",
    "    #Create a prediction array for all the images in the test set using the images from model M1 and M2\n",
    "    for i in range(len(val_set_model1)):\n",
    "        predicted_array = model.predict(np.expand_dims(val_set_model1and2[i],0))\n",
    "        prediction_IMAGE = predicted_array.squeeze()\n",
    "        prediction_images[i] = prediction_IMAGE\n",
    "    #save the prediction array as an npy file\n",
    "    np.save('Model_output_test_'+dataset+'SRCNNmodel4_ultrasound.npy',prediction_images)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "UNet-Implementation.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
