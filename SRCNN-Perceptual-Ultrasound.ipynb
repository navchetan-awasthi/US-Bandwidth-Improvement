{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tOG84vhD_Fgr"
   },
   "outputs": [],
   "source": [
    "#import the neccesary libraries\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import skimage\n",
    "import skimage.transform\n",
    "import os\n",
    "import tensorflow.keras.backend as K\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "import math\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from sobel_edge import sobel \n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "12000\n",
      "13000\n",
      "14000\n",
      "15000\n",
      "16000\n",
      "17000\n",
      "18000\n",
      "19000\n",
      "20000\n",
      "21000\n",
      "22000\n",
      "23000\n",
      "24000\n",
      "25000\n",
      "Done\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "import skimage.transform\n",
    "\n",
    "def CreateSet(input_list,input_dir,output_dir,N_patches,patchsize,H,W):\n",
    "    \"\"\"\n",
    "    Creates an array that can be used as input and output for the model\n",
    "    parameters: input_list, a list with indices of the images that are used\n",
    "                N_patches, the amount of image patches the model creates per image\n",
    "                patchsize, the width and height of the square image patch\n",
    "    \n",
    "    \"\"\"\n",
    "    X = np.zeros((len(input_list)*N_patches, patchsize, patchsize, 1), dtype=np.float32)\n",
    "    y = np.zeros((len(input_list)*N_patches, patchsize, patchsize, 3), dtype=np.float32)\n",
    "    for j in range(N_patches):\n",
    "        for n,i in enumerate(input_list):\n",
    "            #random pixel location\n",
    "            ii = j*len(input_list)+n\n",
    "            xloc = random.randint(0,W-patchsize)\n",
    "            yloc = random.randint(0,H-patchsize)\n",
    "            #input \n",
    "            img_input = Image.open(input_dir+'/input_%03d.png' % (i+1))\n",
    "            in_img_input = tf.keras.preprocessing.image.img_to_array(img_input)\n",
    "            in_img_input = in_img_input[yloc:yloc+patchsize,xloc:xloc+patchsize]\n",
    "            in_img_input = skimage.transform.resize(in_img_input , (patchsize , patchsize , 1) , mode = 'constant' , preserve_range = True)\n",
    "            X[ii] = in_img_input / 255.0\n",
    "\n",
    "            #output\n",
    "            img_output = Image.open(output_dir+'/target_%03d.png' % (i+1))\n",
    "            in_img_output = tf.keras.preprocessing.image.img_to_array(img_output)\n",
    "            in_img_output = in_img_output[yloc:yloc+patchsize,xloc:xloc+patchsize]\n",
    "            in_img_output = skimage.transform.resize(in_img_output , (patchsize , patchsize , 1) , mode = 'constant' , preserve_range = True)\n",
    "            in_img_output = np.concatenate((in_img_output,in_img_output,in_img_output),axis=-1)\n",
    "            y[ii] = in_img_output / 255.0\n",
    "            if ii % 1000 == 0:\n",
    "                print(ii)\n",
    "    print('Done')\n",
    "    return X,y\n",
    "#This function can be used for small datasets \n",
    "#amount of patches per image\n",
    "N_patches = 64\n",
    "#width and height of the patches\n",
    "patchsize = 128\n",
    "#image dimensions\n",
    "H=801\n",
    "W=401\n",
    "input_dir = 'bandLimited'\n",
    "output_dir = 'groundTruth'\n",
    "# input_dir = 'CIRSBandLimited'\n",
    "# output_dir = 'CIRSGroundTruth'\n",
    "# input_dir = 'carotidBandLimited'\n",
    "# output_dir = 'carotidGroundTruth'\n",
    "\n",
    "#Train set is image 1 till 401\n",
    "X_train,y_train = CreateSet(range(401),input_dir,output_dir,N_patches,patchsize,H,W)\n",
    "#validation set is image 402 till 535\n",
    "X_valid,y_valid = CreateSet(range(401,535),input_dir,output_dir,N_patches,patchsize,H,W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Xt_4VuyFAzRI"
   },
   "outputs": [],
   "source": [
    "def SRCNN():\n",
    "    # lrelu = LeakyReLU(alpha=0.1)\n",
    "    SRCNN = tf.keras.Sequential()\n",
    "    SRCNN.add(tf.keras.layers.Conv2D(filters=128, kernel_size= (9,9),  kernel_initializer='glorot_uniform',\n",
    "                     activation='relu', padding='same', input_shape=(None, None, 1)))\n",
    "    SRCNN.add(tf.keras.layers.Conv2D(filters=64, kernel_size= (3,3),  kernel_initializer='glorot_uniform',\n",
    "                     activation='relu', padding='same'))\n",
    "    # SRCNN.add(BatchNormalization())\n",
    "    SRCNN.add(tf.keras.layers.Conv2D(filters=3, kernel_size= (5,5),  kernel_initializer='glorot_uniform',\n",
    "                     activation='linear', padding='same'))\n",
    "    adam = tf.keras.optimizers.Adam(lr=0.0003)\n",
    "    SRCNN.compile(optimizer=adam, loss=loss, loss_weights =loss_weights, metrics=[tf.keras.metrics.RootMeanSquaredError()])\n",
    "    return SRCNN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_shape = (None,None, 3)\n",
    "vgg = VGG16(include_top=False, weights='imagenet', input_shape=image_shape)\n",
    "selectedLayers = ['block1_conv2','block2_conv2','block3_conv3','block4_conv3']\n",
    "selectedOutputs = [vgg.get_layer(i).output for i in selectedLayers]\n",
    "loss_model = tf.keras.Model(inputs=vgg.input, outputs=selectedOutputs)\n",
    "loss_model.trainable = False\n",
    "def perceptual_loss(y_true, y_pred):\n",
    "    mse = 0\n",
    "    for i in range(0,3):\n",
    "        mse = (mse+ K.mean(K.square(loss_model(y_true)[i] - loss_model(y_pred)[i])))\n",
    "    return mse\n",
    "\n",
    "loss = [perceptual_loss, tf.keras.losses.MeanSquaredError]\n",
    "loss_weights = [70,30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 138
    },
    "colab_type": "code",
    "id": "P6bKNYDv8PxF",
    "outputId": "53c556e0-1b76-409a-c4aa-ba58c472930e"
   },
   "outputs": [],
   "source": [
    "#define and compile the model\n",
    "model = SRCNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Hx0xnc4kANzc"
   },
   "outputs": [],
   "source": [
    "model_path = 'model_SRCNN_Perceptual_ultrasound.h5'\n",
    "callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping(patience=10, verbose=1),\n",
    "    tf.keras.callbacks.ReduceLROnPlateau(factor=0.1, patience=5, min_lr=0.0001, verbose=1),\n",
    "    tf.keras.callbacks.ModelCheckpoint(model_path, verbose=1, save_best_only=True, save_weights_only=True)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 2772
    },
    "colab_type": "code",
    "id": "ewoQSgb9-Owo",
    "outputId": "e7d76ce5-ee4d-42a5-9437-9be4dc6ccb98"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, None, None, 128)   31232     \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, None, None, 64)    73792     \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, None, None, 3)     4803      \n",
      "=================================================================\n",
      "Total params: 109,827\n",
      "Trainable params: 109,827\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1616
    },
    "colab_type": "code",
    "id": "jiBmsTy_Anok",
    "outputId": "d350828c-a393-41ad-89f8-38123f726333",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1604/1604 [==============================] - ETA: 0s - loss: 2209.3740 - root_mean_squared_error: 0.1385\n",
      "Epoch 00001: val_loss improved from inf to 2113.26196, saving model to model_SRCNN_Perceptual_ultrasound.h5\n",
      "1604/1604 [==============================] - 130s 81ms/step - loss: 2209.3740 - root_mean_squared_error: 0.1385 - val_loss: 2113.2620 - val_root_mean_squared_error: 0.1184 - lr: 3.0000e-04\n",
      "Epoch 2/100\n",
      "1604/1604 [==============================] - ETA: 0s - loss: 2055.0076 - root_mean_squared_error: 0.1180\n",
      "Epoch 00002: val_loss improved from 2113.26196 to 2061.20410, saving model to model_SRCNN_Perceptual_ultrasound.h5\n",
      "1604/1604 [==============================] - 131s 81ms/step - loss: 2055.0076 - root_mean_squared_error: 0.1180 - val_loss: 2061.2041 - val_root_mean_squared_error: 0.1164 - lr: 3.0000e-04\n",
      "Epoch 3/100\n",
      "1604/1604 [==============================] - ETA: 0s - loss: 2028.3986 - root_mean_squared_error: 0.1176\n",
      "Epoch 00003: val_loss improved from 2061.20410 to 2040.14697, saving model to model_SRCNN_Perceptual_ultrasound.h5\n",
      "1604/1604 [==============================] - 131s 82ms/step - loss: 2028.3986 - root_mean_squared_error: 0.1176 - val_loss: 2040.1470 - val_root_mean_squared_error: 0.1142 - lr: 3.0000e-04\n",
      "Epoch 4/100\n",
      "1604/1604 [==============================] - ETA: 0s - loss: 2013.8739 - root_mean_squared_error: 0.1171\n",
      "Epoch 00004: val_loss improved from 2040.14697 to 2027.15491, saving model to model_SRCNN_Perceptual_ultrasound.h5\n",
      "1604/1604 [==============================] - 130s 81ms/step - loss: 2013.8739 - root_mean_squared_error: 0.1171 - val_loss: 2027.1549 - val_root_mean_squared_error: 0.1142 - lr: 3.0000e-04\n",
      "Epoch 5/100\n",
      "1604/1604 [==============================] - ETA: 0s - loss: 2004.2755 - root_mean_squared_error: 0.1168\n",
      "Epoch 00005: val_loss improved from 2027.15491 to 2022.41626, saving model to model_SRCNN_Perceptual_ultrasound.h5\n",
      "1604/1604 [==============================] - 130s 81ms/step - loss: 2004.2755 - root_mean_squared_error: 0.1168 - val_loss: 2022.4163 - val_root_mean_squared_error: 0.1140 - lr: 3.0000e-04\n",
      "Epoch 6/100\n",
      "1604/1604 [==============================] - ETA: 0s - loss: 1997.8979 - root_mean_squared_error: 0.1169\n",
      "Epoch 00006: val_loss improved from 2022.41626 to 2017.86060, saving model to model_SRCNN_Perceptual_ultrasound.h5\n",
      "1604/1604 [==============================] - 130s 81ms/step - loss: 1997.8979 - root_mean_squared_error: 0.1169 - val_loss: 2017.8606 - val_root_mean_squared_error: 0.1146 - lr: 3.0000e-04\n",
      "Epoch 7/100\n",
      "1604/1604 [==============================] - ETA: 0s - loss: 1992.3956 - root_mean_squared_error: 0.1167\n",
      "Epoch 00007: val_loss improved from 2017.86060 to 2012.68054, saving model to model_SRCNN_Perceptual_ultrasound.h5\n",
      "1604/1604 [==============================] - 130s 81ms/step - loss: 1992.3956 - root_mean_squared_error: 0.1167 - val_loss: 2012.6805 - val_root_mean_squared_error: 0.1164 - lr: 3.0000e-04\n",
      "Epoch 8/100\n",
      "1604/1604 [==============================] - ETA: 0s - loss: 1987.4932 - root_mean_squared_error: 0.1168\n",
      "Epoch 00008: val_loss improved from 2012.68054 to 2003.73132, saving model to model_SRCNN_Perceptual_ultrasound.h5\n",
      "1604/1604 [==============================] - 131s 81ms/step - loss: 1987.4932 - root_mean_squared_error: 0.1168 - val_loss: 2003.7313 - val_root_mean_squared_error: 0.1163 - lr: 3.0000e-04\n",
      "Epoch 9/100\n",
      "1604/1604 [==============================] - ETA: 0s - loss: 1983.7634 - root_mean_squared_error: 0.1168\n",
      "Epoch 00009: val_loss did not improve from 2003.73132\n",
      "1604/1604 [==============================] - 131s 81ms/step - loss: 1983.7634 - root_mean_squared_error: 0.1168 - val_loss: 2006.1393 - val_root_mean_squared_error: 0.1150 - lr: 3.0000e-04\n",
      "Epoch 10/100\n",
      "1604/1604 [==============================] - ETA: 0s - loss: 1980.6113 - root_mean_squared_error: 0.1168\n",
      "Epoch 00010: val_loss improved from 2003.73132 to 2002.01184, saving model to model_SRCNN_Perceptual_ultrasound.h5\n",
      "1604/1604 [==============================] - 129s 81ms/step - loss: 1980.6113 - root_mean_squared_error: 0.1168 - val_loss: 2002.0118 - val_root_mean_squared_error: 0.1154 - lr: 3.0000e-04\n",
      "Epoch 11/100\n",
      "1604/1604 [==============================] - ETA: 0s - loss: 1977.9984 - root_mean_squared_error: 0.1169\n",
      "Epoch 00011: val_loss improved from 2002.01184 to 1997.78760, saving model to model_SRCNN_Perceptual_ultrasound.h5\n",
      "1604/1604 [==============================] - 130s 81ms/step - loss: 1977.9984 - root_mean_squared_error: 0.1169 - val_loss: 1997.7876 - val_root_mean_squared_error: 0.1167 - lr: 3.0000e-04\n",
      "Epoch 12/100\n",
      "1604/1604 [==============================] - ETA: 0s - loss: 1975.5548 - root_mean_squared_error: 0.1169\n",
      "Epoch 00012: val_loss improved from 1997.78760 to 1993.48181, saving model to model_SRCNN_Perceptual_ultrasound.h5\n",
      "1604/1604 [==============================] - 129s 81ms/step - loss: 1975.5548 - root_mean_squared_error: 0.1169 - val_loss: 1993.4818 - val_root_mean_squared_error: 0.1181 - lr: 3.0000e-04\n",
      "Epoch 13/100\n",
      "1604/1604 [==============================] - ETA: 0s - loss: 1973.5884 - root_mean_squared_error: 0.1170\n",
      "Epoch 00013: val_loss improved from 1993.48181 to 1990.38452, saving model to model_SRCNN_Perceptual_ultrasound.h5\n",
      "1604/1604 [==============================] - 129s 81ms/step - loss: 1973.5884 - root_mean_squared_error: 0.1170 - val_loss: 1990.3845 - val_root_mean_squared_error: 0.1185 - lr: 3.0000e-04\n",
      "Epoch 14/100\n",
      "1604/1604 [==============================] - ETA: 0s - loss: 1971.5029 - root_mean_squared_error: 0.1171\n",
      "Epoch 00014: val_loss improved from 1990.38452 to 1988.86731, saving model to model_SRCNN_Perceptual_ultrasound.h5\n",
      "1604/1604 [==============================] - 129s 81ms/step - loss: 1971.5029 - root_mean_squared_error: 0.1171 - val_loss: 1988.8673 - val_root_mean_squared_error: 0.1182 - lr: 3.0000e-04\n",
      "Epoch 15/100\n",
      "1604/1604 [==============================] - ETA: 0s - loss: 1969.9050 - root_mean_squared_error: 0.1172\n",
      "Epoch 00015: val_loss improved from 1988.86731 to 1988.22571, saving model to model_SRCNN_Perceptual_ultrasound.h5\n",
      "1604/1604 [==============================] - 129s 80ms/step - loss: 1969.9050 - root_mean_squared_error: 0.1172 - val_loss: 1988.2257 - val_root_mean_squared_error: 0.1178 - lr: 3.0000e-04\n",
      "Epoch 16/100\n",
      "1604/1604 [==============================] - ETA: 0s - loss: 1968.2881 - root_mean_squared_error: 0.1173\n",
      "Epoch 00016: val_loss improved from 1988.22571 to 1987.59375, saving model to model_SRCNN_Perceptual_ultrasound.h5\n",
      "1604/1604 [==============================] - 129s 80ms/step - loss: 1968.2881 - root_mean_squared_error: 0.1173 - val_loss: 1987.5938 - val_root_mean_squared_error: 0.1181 - lr: 3.0000e-04\n",
      "Epoch 17/100\n",
      "1604/1604 [==============================] - ETA: 0s - loss: 1966.7887 - root_mean_squared_error: 0.1174\n",
      "Epoch 00017: val_loss improved from 1987.59375 to 1986.52307, saving model to model_SRCNN_Perceptual_ultrasound.h5\n",
      "1604/1604 [==============================] - 129s 80ms/step - loss: 1966.7887 - root_mean_squared_error: 0.1174 - val_loss: 1986.5231 - val_root_mean_squared_error: 0.1186 - lr: 3.0000e-04\n",
      "Epoch 18/100\n",
      "1604/1604 [==============================] - ETA: 0s - loss: 1965.5106 - root_mean_squared_error: 0.1177\n",
      "Epoch 00018: val_loss improved from 1986.52307 to 1985.24902, saving model to model_SRCNN_Perceptual_ultrasound.h5\n",
      "1604/1604 [==============================] - 130s 81ms/step - loss: 1965.5106 - root_mean_squared_error: 0.1177 - val_loss: 1985.2490 - val_root_mean_squared_error: 0.1184 - lr: 3.0000e-04\n",
      "Epoch 19/100\n",
      "1604/1604 [==============================] - ETA: 0s - loss: 1964.1899 - root_mean_squared_error: 0.1179\n",
      "Epoch 00019: val_loss improved from 1985.24902 to 1984.17114, saving model to model_SRCNN_Perceptual_ultrasound.h5\n",
      "1604/1604 [==============================] - 130s 81ms/step - loss: 1964.1899 - root_mean_squared_error: 0.1179 - val_loss: 1984.1711 - val_root_mean_squared_error: 0.1177 - lr: 3.0000e-04\n",
      "Epoch 20/100\n",
      "1604/1604 [==============================] - ETA: 0s - loss: 1962.9402 - root_mean_squared_error: 0.1181\n",
      "Epoch 00020: val_loss improved from 1984.17114 to 1983.62659, saving model to model_SRCNN_Perceptual_ultrasound.h5\n",
      "1604/1604 [==============================] - 129s 80ms/step - loss: 1962.9402 - root_mean_squared_error: 0.1181 - val_loss: 1983.6266 - val_root_mean_squared_error: 0.1183 - lr: 3.0000e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/100\n",
      "1604/1604 [==============================] - ETA: 0s - loss: 1961.9257 - root_mean_squared_error: 0.1184\n",
      "Epoch 00021: val_loss improved from 1983.62659 to 1982.56067, saving model to model_SRCNN_Perceptual_ultrasound.h5\n",
      "1604/1604 [==============================] - 129s 80ms/step - loss: 1961.9257 - root_mean_squared_error: 0.1184 - val_loss: 1982.5607 - val_root_mean_squared_error: 0.1186 - lr: 3.0000e-04\n",
      "Epoch 22/100\n",
      "1604/1604 [==============================] - ETA: 0s - loss: 1960.8684 - root_mean_squared_error: 0.1186\n",
      "Epoch 00022: val_loss improved from 1982.56067 to 1982.03223, saving model to model_SRCNN_Perceptual_ultrasound.h5\n",
      "1604/1604 [==============================] - 129s 80ms/step - loss: 1960.8684 - root_mean_squared_error: 0.1186 - val_loss: 1982.0322 - val_root_mean_squared_error: 0.1189 - lr: 3.0000e-04\n",
      "Epoch 23/100\n",
      "1604/1604 [==============================] - ETA: 0s - loss: 1959.9551 - root_mean_squared_error: 0.1189\n",
      "Epoch 00023: val_loss improved from 1982.03223 to 1981.47998, saving model to model_SRCNN_Perceptual_ultrasound.h5\n",
      "1604/1604 [==============================] - 129s 80ms/step - loss: 1959.9551 - root_mean_squared_error: 0.1189 - val_loss: 1981.4800 - val_root_mean_squared_error: 0.1195 - lr: 3.0000e-04\n",
      "Epoch 24/100\n",
      "1604/1604 [==============================] - ETA: 0s - loss: 1959.0027 - root_mean_squared_error: 0.1192\n",
      "Epoch 00024: val_loss improved from 1981.47998 to 1980.74390, saving model to model_SRCNN_Perceptual_ultrasound.h5\n",
      "1604/1604 [==============================] - 129s 80ms/step - loss: 1959.0027 - root_mean_squared_error: 0.1192 - val_loss: 1980.7439 - val_root_mean_squared_error: 0.1203 - lr: 3.0000e-04\n",
      "Epoch 25/100\n",
      "1604/1604 [==============================] - ETA: 0s - loss: 1958.2040 - root_mean_squared_error: 0.1195\n",
      "Epoch 00025: val_loss did not improve from 1980.74390\n",
      "1604/1604 [==============================] - 128s 80ms/step - loss: 1958.2040 - root_mean_squared_error: 0.1195 - val_loss: 1980.9949 - val_root_mean_squared_error: 0.1205 - lr: 3.0000e-04\n",
      "Epoch 26/100\n",
      "1604/1604 [==============================] - ETA: 0s - loss: 1957.3383 - root_mean_squared_error: 0.1198\n",
      "Epoch 00026: val_loss improved from 1980.74390 to 1979.49182, saving model to model_SRCNN_Perceptual_ultrasound.h5\n",
      "1604/1604 [==============================] - 129s 80ms/step - loss: 1957.3383 - root_mean_squared_error: 0.1198 - val_loss: 1979.4918 - val_root_mean_squared_error: 0.1211 - lr: 3.0000e-04\n",
      "Epoch 27/100\n",
      "1604/1604 [==============================] - ETA: 0s - loss: 1956.5089 - root_mean_squared_error: 0.1201\n",
      "Epoch 00027: val_loss did not improve from 1979.49182\n",
      "1604/1604 [==============================] - 129s 80ms/step - loss: 1956.5089 - root_mean_squared_error: 0.1201 - val_loss: 1979.7633 - val_root_mean_squared_error: 0.1213 - lr: 3.0000e-04\n",
      "Epoch 28/100\n",
      "1604/1604 [==============================] - ETA: 0s - loss: 1955.7606 - root_mean_squared_error: 0.1204\n",
      "Epoch 00028: val_loss improved from 1979.49182 to 1979.36633, saving model to model_SRCNN_Perceptual_ultrasound.h5\n",
      "1604/1604 [==============================] - 130s 81ms/step - loss: 1955.7606 - root_mean_squared_error: 0.1204 - val_loss: 1979.3663 - val_root_mean_squared_error: 0.1210 - lr: 3.0000e-04\n",
      "Epoch 29/100\n",
      "1604/1604 [==============================] - ETA: 0s - loss: 1954.9197 - root_mean_squared_error: 0.1207\n",
      "Epoch 00029: val_loss improved from 1979.36633 to 1979.15271, saving model to model_SRCNN_Perceptual_ultrasound.h5\n",
      "1604/1604 [==============================] - 129s 80ms/step - loss: 1954.9197 - root_mean_squared_error: 0.1207 - val_loss: 1979.1527 - val_root_mean_squared_error: 0.1208 - lr: 3.0000e-04\n",
      "Epoch 30/100\n",
      "1604/1604 [==============================] - ETA: 0s - loss: 1954.1656 - root_mean_squared_error: 0.1209\n",
      "Epoch 00030: val_loss improved from 1979.15271 to 1978.44702, saving model to model_SRCNN_Perceptual_ultrasound.h5\n",
      "1604/1604 [==============================] - 129s 80ms/step - loss: 1954.1656 - root_mean_squared_error: 0.1209 - val_loss: 1978.4470 - val_root_mean_squared_error: 0.1216 - lr: 3.0000e-04\n",
      "Epoch 31/100\n",
      "1604/1604 [==============================] - ETA: 0s - loss: 1953.5513 - root_mean_squared_error: 0.1212\n",
      "Epoch 00031: val_loss improved from 1978.44702 to 1978.30896, saving model to model_SRCNN_Perceptual_ultrasound.h5\n",
      "1604/1604 [==============================] - 129s 80ms/step - loss: 1953.5513 - root_mean_squared_error: 0.1212 - val_loss: 1978.3090 - val_root_mean_squared_error: 0.1213 - lr: 3.0000e-04\n",
      "Epoch 32/100\n",
      "1604/1604 [==============================] - ETA: 0s - loss: 1952.7878 - root_mean_squared_error: 0.1214\n",
      "Epoch 00032: val_loss improved from 1978.30896 to 1977.34583, saving model to model_SRCNN_Perceptual_ultrasound.h5\n",
      "1604/1604 [==============================] - 128s 80ms/step - loss: 1952.7878 - root_mean_squared_error: 0.1214 - val_loss: 1977.3458 - val_root_mean_squared_error: 0.1215 - lr: 3.0000e-04\n",
      "Epoch 33/100\n",
      "1604/1604 [==============================] - ETA: 0s - loss: 1952.1471 - root_mean_squared_error: 0.1216\n",
      "Epoch 00033: val_loss improved from 1977.34583 to 1977.19312, saving model to model_SRCNN_Perceptual_ultrasound.h5\n",
      "1604/1604 [==============================] - 129s 80ms/step - loss: 1952.1471 - root_mean_squared_error: 0.1216 - val_loss: 1977.1931 - val_root_mean_squared_error: 0.1211 - lr: 3.0000e-04\n",
      "Epoch 34/100\n",
      "1604/1604 [==============================] - ETA: 0s - loss: 1951.5195 - root_mean_squared_error: 0.1218\n",
      "Epoch 00034: val_loss improved from 1977.19312 to 1976.43518, saving model to model_SRCNN_Perceptual_ultrasound.h5\n",
      "1604/1604 [==============================] - 128s 80ms/step - loss: 1951.5195 - root_mean_squared_error: 0.1218 - val_loss: 1976.4352 - val_root_mean_squared_error: 0.1213 - lr: 3.0000e-04\n",
      "Epoch 35/100\n",
      "1604/1604 [==============================] - ETA: 0s - loss: 1950.9285 - root_mean_squared_error: 0.1220\n",
      "Epoch 00035: val_loss improved from 1976.43518 to 1975.88086, saving model to model_SRCNN_Perceptual_ultrasound.h5\n",
      "1604/1604 [==============================] - 130s 81ms/step - loss: 1950.9285 - root_mean_squared_error: 0.1220 - val_loss: 1975.8809 - val_root_mean_squared_error: 0.1216 - lr: 3.0000e-04\n",
      "Epoch 36/100\n",
      "1604/1604 [==============================] - ETA: 0s - loss: 1950.2736 - root_mean_squared_error: 0.1221\n",
      "Epoch 00036: val_loss improved from 1975.88086 to 1975.37524, saving model to model_SRCNN_Perceptual_ultrasound.h5\n",
      "1604/1604 [==============================] - 129s 80ms/step - loss: 1950.2736 - root_mean_squared_error: 0.1221 - val_loss: 1975.3752 - val_root_mean_squared_error: 0.1214 - lr: 3.0000e-04\n",
      "Epoch 37/100\n",
      "1604/1604 [==============================] - ETA: 0s - loss: 1949.6722 - root_mean_squared_error: 0.1223\n",
      "Epoch 00037: val_loss improved from 1975.37524 to 1975.26440, saving model to model_SRCNN_Perceptual_ultrasound.h5\n",
      "1604/1604 [==============================] - 130s 81ms/step - loss: 1949.6722 - root_mean_squared_error: 0.1223 - val_loss: 1975.2644 - val_root_mean_squared_error: 0.1218 - lr: 3.0000e-04\n",
      "Epoch 38/100\n",
      "1604/1604 [==============================] - ETA: 0s - loss: 1949.2622 - root_mean_squared_error: 0.1225\n",
      "Epoch 00038: val_loss improved from 1975.26440 to 1974.91797, saving model to model_SRCNN_Perceptual_ultrasound.h5\n",
      "1604/1604 [==============================] - 128s 80ms/step - loss: 1949.2622 - root_mean_squared_error: 0.1225 - val_loss: 1974.9180 - val_root_mean_squared_error: 0.1218 - lr: 3.0000e-04\n",
      "Epoch 39/100\n",
      "1604/1604 [==============================] - ETA: 0s - loss: 1948.6688 - root_mean_squared_error: 0.1226\n",
      "Epoch 00039: val_loss improved from 1974.91797 to 1974.15833, saving model to model_SRCNN_Perceptual_ultrasound.h5\n",
      "1604/1604 [==============================] - 129s 81ms/step - loss: 1948.6688 - root_mean_squared_error: 0.1226 - val_loss: 1974.1583 - val_root_mean_squared_error: 0.1224 - lr: 3.0000e-04\n",
      "Epoch 40/100\n",
      "1604/1604 [==============================] - ETA: 0s - loss: 1948.1812 - root_mean_squared_error: 0.1227\n",
      "Epoch 00040: val_loss improved from 1974.15833 to 1974.12341, saving model to model_SRCNN_Perceptual_ultrasound.h5\n",
      "1604/1604 [==============================] - 129s 80ms/step - loss: 1948.1812 - root_mean_squared_error: 0.1227 - val_loss: 1974.1234 - val_root_mean_squared_error: 0.1222 - lr: 3.0000e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/100\n",
      "1604/1604 [==============================] - ETA: 0s - loss: 1947.6954 - root_mean_squared_error: 0.1229\n",
      "Epoch 00041: val_loss improved from 1974.12341 to 1973.30811, saving model to model_SRCNN_Perceptual_ultrasound.h5\n",
      "1604/1604 [==============================] - 129s 81ms/step - loss: 1947.6954 - root_mean_squared_error: 0.1229 - val_loss: 1973.3081 - val_root_mean_squared_error: 0.1220 - lr: 3.0000e-04\n",
      "Epoch 42/100\n",
      "1604/1604 [==============================] - ETA: 0s - loss: 1947.2200 - root_mean_squared_error: 0.1230\n",
      "Epoch 00042: val_loss did not improve from 1973.30811\n",
      "1604/1604 [==============================] - 129s 80ms/step - loss: 1947.2200 - root_mean_squared_error: 0.1230 - val_loss: 1974.2150 - val_root_mean_squared_error: 0.1221 - lr: 3.0000e-04\n",
      "Epoch 43/100\n",
      "1604/1604 [==============================] - ETA: 0s - loss: 1946.7924 - root_mean_squared_error: 0.1232\n",
      "Epoch 00043: val_loss did not improve from 1973.30811\n",
      "1604/1604 [==============================] - 129s 80ms/step - loss: 1946.7924 - root_mean_squared_error: 0.1232 - val_loss: 1973.5149 - val_root_mean_squared_error: 0.1223 - lr: 3.0000e-04\n",
      "Epoch 44/100\n",
      "1604/1604 [==============================] - ETA: 0s - loss: 1946.4197 - root_mean_squared_error: 0.1233\n",
      "Epoch 00044: val_loss improved from 1973.30811 to 1972.72571, saving model to model_SRCNN_Perceptual_ultrasound.h5\n",
      "1604/1604 [==============================] - 129s 80ms/step - loss: 1946.4197 - root_mean_squared_error: 0.1233 - val_loss: 1972.7257 - val_root_mean_squared_error: 0.1224 - lr: 3.0000e-04\n",
      "Epoch 45/100\n",
      "1604/1604 [==============================] - ETA: 0s - loss: 1946.0215 - root_mean_squared_error: 0.1234\n",
      "Epoch 00045: val_loss did not improve from 1972.72571\n",
      "1604/1604 [==============================] - 129s 80ms/step - loss: 1946.0215 - root_mean_squared_error: 0.1234 - val_loss: 1973.6514 - val_root_mean_squared_error: 0.1219 - lr: 3.0000e-04\n",
      "Epoch 46/100\n",
      " 378/1604 [======>.......................] - ETA: 1:20 - loss: 1945.1198 - root_mean_squared_error: 0.1236"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-590a21a242fe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m results = model.fit(X_train,y_train, epochs=100, callbacks=callbacks,batch_size = 16,\n\u001b[0m\u001b[1;32m      3\u001b[0m                     validation_data=(X_valid,y_valid),shuffle=False)\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    853\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m               \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmp_logs\u001b[0m  \u001b[0;31m# No error, now safe to assign to logs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m         \u001b[0mepoch_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    387\u001b[0m     \"\"\"\n\u001b[1;32m    388\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_call_train_batch_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 389\u001b[0;31m       \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    390\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    391\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_process_logs\u001b[0;34m(self, logs)\u001b[0m\n\u001b[1;32m    263\u001b[0m     \u001b[0;34m\"\"\"Turns tensors into numpy arrays or Python scalars.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 265\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    266\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36mto_numpy_or_python_type\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    521\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    522\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 523\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    524\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    615\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    616\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 617\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    618\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    619\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    615\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    616\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 617\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    618\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    619\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36m_to_single_numpy_or_python_type\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    517\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 519\u001b[0;31m       \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    520\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    521\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    959\u001b[0m     \"\"\"\n\u001b[1;32m    960\u001b[0m     \u001b[0;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 961\u001b[0;31m     \u001b[0mmaybe_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    962\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    963\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    925\u001b[0m     \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    926\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 927\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    928\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    929\u001b[0m       \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#train the model\n",
    "results = model.fit(X_train,y_train, epochs=100, callbacks=callbacks,batch_size = 16,\n",
    "                    validation_data=(X_valid,y_valid),shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uXgvQE67EC8G"
   },
   "outputs": [],
   "source": [
    "#load the model\n",
    "model.load_weights(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualise the accuracy and losses of the model\n",
    "# list all data in history\n",
    "print(results.history.keys())\n",
    "# summarize history for accuracy\n",
    "plt.plot(results.history['root_mean_squared_error'])\n",
    "plt.plot(results.history['val_root_mean_squared_error'])\n",
    "plt.title('model root_mean_squared_error')\n",
    "plt.ylabel('root_mean_squared_error')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(results.history['loss'])\n",
    "plt.plot(results.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_set_indices = range(535)\n",
    "Train_set_X = np.zeros((len(Train_set_indices), 801, 401,1), dtype=np.float32)\n",
    "for i in Train_set_indices:\n",
    "    img = Image.open('bandLimited/input_%03d.png' % (i+1))\n",
    "    in_img_input = tf.keras.preprocessing.image.img_to_array(img)\n",
    "    in_img_input = skimage.transform.resize(in_img_input , (801 , 401 , 1) , mode = 'constant' , preserve_range = True)\n",
    "    Train_set_X[i] =in_img_input / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_images = np.zeros((len(Train_set_X),801,401),dtype=np.float32)\n",
    "for i in Train_set_indices:\n",
    "    prediction_image = model.predict(np.expand_dims(Train_set_X[i] , 0))\n",
    "    prediction_image = prediction_image[:,:,:,0]\n",
    "    prediction_image = prediction_image.squeeze()*255.0\n",
    "    prediction_image  = Image.fromarray(prediction_image)\n",
    "    if prediction_image.mode == \"F\":\n",
    "        prediction_image = prediction_image.convert('RGB')\n",
    "    prediction_image.save('bandlimited_SRCNNmodel1/input_%03d.png' % (i+1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n",
      "Done\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "def CreateTestSet(test_set_indices,input_dir_test,output_dir_test):\n",
    "    \"\"\"\n",
    "    Function that reads in the test sets images as arrays\n",
    "    parameters:test_set_indices: The indices of the the images in the test set\n",
    "                 input_dir_test: The directory where the input png images are stored\n",
    "                output_dir_test: The directory where the output png images are stored\n",
    "    \"\"\"\n",
    "    Test_set_X = np.zeros((len(test_set_indices), 801, 401, 1), dtype=np.float32)\n",
    "    Test_set_y = np.zeros((len(test_set_indices), 801, 401, 1), dtype=np.float32)\n",
    "    for i,n in enumerate(test_set_indices):\n",
    "        img = Image.open(input_dir_test+'/input_%03d.png' % (n+1))\n",
    "        in_img_input = tf.keras.preprocessing.image.img_to_array(img)\n",
    "        in_img_input = skimage.transform.resize(in_img_input , (801 , 401 , 1) , mode = 'constant' , preserve_range = True)\n",
    "        Test_set_X[i] =in_img_input / 255.0\n",
    "\n",
    "        img = Image.open(output_dir_test+'/target_%03d.png' % (n+1))\n",
    "        in_img_output = tf.keras.preprocessing.image.img_to_array(img)\n",
    "        in_img_output = skimage.transform.resize(in_img_output , (801 , 401 , 1) , mode = 'constant' , preserve_range = True)\n",
    "        Test_set_y[i] =in_img_output / 255.0    \n",
    "    print('Done')\n",
    "    return Test_set_X, Test_set_y\n",
    "#Save numpy files for all the images in the 3 test sets \n",
    "for dataset in ['','CIRS_','carotid_']:\n",
    "    if dataset == '':\n",
    "        test_set_indices = range(535,669)\n",
    "        input_dir_test = 'bandLimited'\n",
    "        output_dir_test = 'groundTruth'\n",
    "    if dataset == 'CIRS_':\n",
    "        test_set_indices = range(11)\n",
    "        input_dir_test = 'CIRSBandLimited'\n",
    "        output_dir_test = 'CIRSGroundTruth'\n",
    "    if dataset =='carotid_':\n",
    "        test_set_indices = range(70)\n",
    "        input_dir_test = 'carotidBandLimited'\n",
    "        output_dir_test = 'carotidGroundTruth'\n",
    "    Test_set_X, Test_set_y = CreateTestSet(test_set_indices,input_dir_test,output_dir_test)\n",
    "    prediction_images = np.zeros((len(Test_set_X),801,401),dtype=np.float32)\n",
    "    for i in range(len(Test_set_X)):\n",
    "        prediction_image = model.predict(np.expand_dims(Test_set_X[i] , 0))\n",
    "        prediction_image = prediction_image[:,:,:,0]\n",
    "        prediction_images[i] = prediction_image.squeeze()\n",
    "    np.save('Model_output_test_'+dataset+'SRCNNmodel1_ultrasound.npy',prediction_images)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "UNet-Implementation.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
